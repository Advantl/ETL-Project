# ETL-Project
Python-based ETL pipeline

## Контекст
Организация, предоставляющая образовательные услуги, осуществила интеграцию своего редактора кода внутрь обучающей системы (ЛМС) корпоративного клиента (онлайн-университет). Каждый день тысячи студентов этого университета решают разнообразные задачи в редакторе и когда они отправляют свои решения, запросы попадают на сервер образовательной организации. Она осуществляет обработку этих данных и возвращает ответы, которые не только позволяют выставить оценку студентам, но и содержат информацию об их успехах и прогрессе. В базе данных сохраняется подробная информация о том, какие студенты решали определенные задачи, какой код они написали, когда были предприняты попытки решения и были ли они успешными. Эти данные служат основой для оценки эффективности образовательного процесса, предоставления обратной связи студентам и определения наиболее результативных подходов к обучению, что способствует постоянному совершенствованию учебной программы и повышению качества образования.

## Постановка задачи.
Написать скрипт, который будет собирать, обрабатывать и хранить данные об использовании студентами редактора кода. Взаимодействие с сервером образовательной организации будет производиться через его API. Для получения информацию о работе студентов в редакторе будут отправляться запросы на определённый адрес (API endpoint) с указанными параметрами. Полученные данные будут возвращаться в формате JSON, из которого необходимо извлекать только информацию, определённую бизнес-требованиями, и загружать её в базу данных PostgreSQL. В дальнейшем весь процесс будет автоматизирован: от запроса к API до сохранения данных в PostgreSQL.

## Архитектура

### Первый скрипт: получение и загрузка в базу исторических данных.
#### 1️. Extract: обращение к API и получение данных
#### 2️. Transform: обработка и подготовка данных 
#### 3️⃣. Load: загрузка данных в локальную базу PostgreSQL

Для удобства отслеживания процесса загрузки в БД реализован прогресс бар.

### Второй скрипт: получение и загрузка данных за прошедшие сутки. 
#### 1️. Extract: обращение к API и получение данных
#### 2️. Transform: обработка и подготовка данных 
#### 3️⃣. Load: загрузка данных в локальную базу PostgreSQL
#### 4️⃣. Подготовка и выгрузка статистики в Google Sheets
#### 5️⃣. Отправка уведомления на почту

Скрипт регистрирует важные события в лог-файлах. Каждый день создается отдельный лог-файл, имя которого соответствует дате записи событий. Система хранения логов настроена на сохранение только последних трёх дней. Более старые файлы автоматически удаляются. Таким образом, в папке с логами всегда присутствуют только записи за последние 72 часа.

### Структура локальной базы PostgreSQL  
•	user_id - строковый айди пользователя  
•	oauth_consumer_key - уникальный токен клиента  
•	lis_result_sourcedid - ссылка на блок, в котором находится задача в ЛМС  
•	lis_outcome_service_url - URL адрес в ЛМС, куда мы шлем оценку  
•	is_correct - была ли попытка верной (null, если это run)  
•	attempt_type - ран или сабмит  
•	created_at - дата и время попытки  

### Проект содержит следующие файлы:  
- [Скрипт 1](https://github.com/Advantl/ETL-Project/blob/main/etl_script_1.ipynb)
- [Скрипт 2](https://github.com/Advantl/ETL-Project/blob/main/etl_script_2.ipynb)
- [Образец лог файла.](https://github.com/Advantl/ETL-Project/blob/main/2025-07-24.log)
- [Скрин письма с почты.](https://github.com/Advantl/ETL-Project/blob/main/email_screenshot.jpg)
- [Ссылка на таблицу со статистикой.](https://docs.google.com/spreadsheets/d/1GWKQpj-kJ57ex0s7TYY4-zDh_P4BMtq5UXcl-qUl6mE/edit?gid=1320758862#gid=1320758862)
